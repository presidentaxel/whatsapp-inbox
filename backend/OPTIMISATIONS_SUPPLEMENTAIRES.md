# üöÄ Optimisations suppl√©mentaires appliqu√©es

## ‚úÖ Ce qui a √©t√© fait

### 1. Cache pour `/auth/me` ‚ö° (Gain attendu: -80% latence)

**Probl√®me:** `/auth/me` prenait 1.01s et est appel√© √† **chaque requ√™te authentifi√©e**.

**Solution appliqu√©e:**
- Cache de l'utilisateur authentifi√© avec TTL de 2 minutes
- Bas√© sur le hash du token JWT
- Premi√®re requ√™te: 1.01s, requ√™tes suivantes: ~10ms

**Impact attendu:**
- `/auth/me`: 1.01s ‚Üí **~50ms en moyenne**
- **Toutes les routes authentifi√©es seront plus rapides** (car elles appellent get_current_user)

---

### 2. Cache pour `get_conversation_by_id()` (Gain: -70%)

**Probl√®me:** Appel√© plusieurs fois par requ√™te, toujours en DB.

**Solution appliqu√©e:**
- Cache avec TTL de 1 minute
- Les conversations changent rarement

**Impact attendu:**
- Premi√®re lecture: ~200ms, suivantes: ~10ms

---

## üéØ Optimisations √† faire manuellement (SQL)

### 3. Ajouter des index Supabase

Si vous avez acc√®s √† Supabase, ex√©cutez ces requ√™tes SQL pour acc√©l√©rer les queries :

```sql
-- Index pour les conversations (optimise list_conversations)
CREATE INDEX IF NOT EXISTS idx_conversations_account_updated 
ON conversations(account_id, updated_at DESC);

-- Index pour les messages (optimise get_messages)
CREATE INDEX IF NOT EXISTS idx_messages_conversation_timestamp 
ON messages(conversation_id, timestamp DESC);

-- Index pour les contacts
CREATE INDEX IF NOT EXISTS idx_conversations_contact 
ON conversations(contact_id);

-- Index pour les accounts (si pas d√©j√† pr√©sent)
CREATE INDEX IF NOT EXISTS idx_accounts_phone_number_id 
ON whatsapp_accounts(phone_number_id);

-- Index pour les app_users
CREATE INDEX IF NOT EXISTS idx_app_users_user_id 
ON app_users(user_id);

-- Index pour les role assignments
CREATE INDEX IF NOT EXISTS idx_user_roles_user_id 
ON app_user_roles(user_id);
```

**Impact attendu:**
- `/conversations`: 798ms ‚Üí **~200-300ms**
- `/messages/{conversation_id}`: 873ms ‚Üí **~200-300ms**

---

### 4. Optimiser les requ√™tes admin (si n√©cessaire)

Si les routes admin restent lentes apr√®s les caches, vous pouvez :

**Option A - D√©normaliser (recommand√©) :**
```sql
-- Ajouter une colonne JSON pour √©viter les JOINs
ALTER TABLE app_users ADD COLUMN roles_cache JSONB;

-- Trigger pour maintenir √† jour
CREATE OR REPLACE FUNCTION update_user_roles_cache()
RETURNS TRIGGER AS $$
BEGIN
  UPDATE app_users 
  SET roles_cache = (
    SELECT json_agg(json_build_object(
      'role_id', r.role_id,
      'account_id', r.account_id,
      'role_name', ar.name
    ))
    FROM app_user_roles r
    JOIN app_roles ar ON ar.id = r.role_id
    WHERE r.user_id = NEW.user_id
  )
  WHERE user_id = NEW.user_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_update_user_roles_cache
AFTER INSERT OR UPDATE OR DELETE ON app_user_roles
FOR EACH ROW EXECUTE FUNCTION update_user_roles_cache();
```

**Option B - Utiliser des vues mat√©rialis√©es :**
```sql
CREATE MATERIALIZED VIEW mv_users_with_roles AS
SELECT 
  u.*,
  json_agg(json_build_object(
    'role_id', r.role_id,
    'account_id', r.account_id,
    'role_name', ar.name
  )) as roles
FROM app_users u
LEFT JOIN app_user_roles r ON r.user_id = u.user_id
LEFT JOIN app_roles ar ON ar.id = r.role_id
GROUP BY u.user_id;

CREATE UNIQUE INDEX ON mv_users_with_roles(user_id);

-- Rafra√Æchir toutes les 5 minutes
-- (ou cr√©er un trigger pour rafra√Æchir apr√®s chaque modification)
```

---

## üìä Impact global attendu

| Endpoint | Avant | Apr√®s | Gain |
|----------|-------|-------|------|
| `/auth/me` | 1010ms | **~50ms** | **-95%** ‚úÖ |
| `/accounts` | 1120ms | **~400ms** | **-64%** üîÑ |
| `/admin/*` | 1220ms | **~500ms** | **-59%** üîÑ |
| `/conversations` | 798ms | **~250ms** | **-69%** üîÑ |
| `/messages/{id}` | 873ms | **~300ms** | **-66%** üîÑ |
| `/bot/profile` | 679ms | **~100ms** | **-85%** ‚úÖ |

**L√©gende:**
- ‚úÖ Cache appliqu√© automatiquement
- üîÑ N√©cessite les index SQL

---

## üîß Autres optimisations possibles (optionnel)

### 5. Migrer vers asyncpg (long terme)

Le client Supabase Python est synchrone. Pour de meilleures performances :

```python
# Installer asyncpg
pip install asyncpg

# Utiliser asyncpg directement
import asyncpg

pool = await asyncpg.create_pool(
    host='db.xxx.supabase.co',
    port=5432,
    user='postgres',
    password='...',
    database='postgres',
    min_size=5,
    max_size=20
)

async def get_conversation_by_id(conversation_id: str):
    async with pool.acquire() as conn:
        row = await conn.fetchrow(
            'SELECT * FROM conversations WHERE id = $1 LIMIT 1',
            conversation_id
        )
        return dict(row) if row else None
```

**Avantages:**
- Vraiment async (pas de threadpool)
- Connection pooling natif
- Plus rapide (~30% de gain)

**Inconv√©nients:**
- N√©cessite de r√©√©crire toutes les requ√™tes
- Perte du query builder Supabase
- Plus de code √† maintenir

---

### 6. Ajouter un cache Redis (production)

Pour un cache partag√© entre instances :

```python
# requirements.txt
redis>=4.5.0
aioredis>=2.0.1

# backend/app/core/redis_cache.py
import aioredis
import json

redis = await aioredis.from_url("redis://localhost:6379")

async def get_cached(key: str):
    value = await redis.get(key)
    return json.loads(value) if value else None

async def set_cached(key: str, value: any, ttl: int):
    await redis.setex(key, ttl, json.dumps(value))
```

**Avantages:**
- Cache partag√© entre instances
- Persistant (survit aux red√©marrages)
- Tr√®s rapide (~1ms)

---

### 7. Pagination cursor-based (au lieu de offset)

Pour `/conversations` et `/messages`, utiliser la pagination par cursor :

**Avant (offset):**
```sql
SELECT * FROM conversations 
WHERE account_id = $1 
ORDER BY updated_at DESC 
LIMIT 50 OFFSET 100;  -- Lent sur grandes tables
```

**Apr√®s (cursor):**
```sql
SELECT * FROM conversations 
WHERE account_id = $1 
  AND updated_at < $2  -- Cursor
ORDER BY updated_at DESC 
LIMIT 50;  -- Rapide avec index
```

**Impact:** 50-70% plus rapide sur les grandes tables.

---

## üéØ Plan d'action recommand√©

### Imm√©diat (fait automatiquement) ‚úÖ
1. Cache `/auth/me` ‚Üê **D√©j√† appliqu√©**
2. Cache `get_conversation_by_id` ‚Üê **D√©j√† appliqu√©**

### Court terme (5 min) üî¥
3. Ajouter les index SQL dans Supabase ‚Üê **√Ä faire maintenant**

### Moyen terme (si besoin) üü°
4. Optimiser les routes admin si elles restent lentes
5. V√©rifier les autres requ√™tes lentes dans Grafana

### Long terme (optionnel) üü¢
6. Migrer vers asyncpg
7. Ajouter Redis en production
8. Optimiser la pagination

---

## ‚úÖ Comment tester

```powershell
# 1. Red√©marrer
docker-compose restart backend

# 2. V√©rifier les logs (chercher "Cache HIT")
docker-compose logs -f backend | Select-String -Pattern "Cache"

# 3. Tester /auth/me (devrait √™tre beaucoup plus rapide)
# Premi√®re requ√™te: ~1s, suivantes: ~50ms
curl http://localhost:8000/auth/me -H "Authorization: Bearer YOUR_TOKEN"

# 4. Attendre 10-15 minutes et v√©rifier Grafana
# - /auth/me devrait passer de 1.01s √† ~100-200ms en moyenne
# - Toutes les autres routes devraient √™tre plus rapides aussi
```

---

## üìà R√©sultats attendus dans Grafana

**Apr√®s red√©marrage (avec cache auth + conversation) :**
- P50 global: 800ms ‚Üí **~300ms** (-62%)
- P95 global: 1000ms ‚Üí **~500ms** (-50%)
- /auth/me: 1010ms ‚Üí **~100ms** (-90%)

**Apr√®s ajout des index SQL :**
- P50 global: ~300ms ‚Üí **~150ms** (-50%)
- P95 global: ~500ms ‚Üí **~300ms** (-40%)
- /conversations: 798ms ‚Üí **~200ms** (-75%)
- /messages: 873ms ‚Üí **~250ms** (-71%)

---

**Faites les changements SQL et observez les r√©sultats dans 15-20 minutes ! üöÄ**

